{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25382,
     "status": "ok",
     "timestamp": 1586878778157,
     "user": {
      "displayName": "Fred Che",
      "photoUrl": "",
      "userId": "07612464138287230381"
     },
     "user_tz": -120
    },
    "id": "G6lD9Q08VX9L",
    "outputId": "ed346101-0a5a-462b-a793-592a8ecbe6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Colab?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# google colab configurations \n",
    "# these might change\n",
    "DATA_GENERATION = '13kwW8C01etWsqTYoE2eeFlD4Ft9YVhrw'\n",
    "DATA_GENERATION_FILE = 'datageneration.py'\n",
    "\n",
    "HELPERS = '1zskLM0-ZtEQYVI7zvd2ePqtkTOkJmVIL'\n",
    "HELPERS_FILE = 'helpers.py'\n",
    "\n",
    "google_colab = input('Running on Colab?\\n')\n",
    "if google_colab=='yes' : \n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "    datageneration = drive.CreateFile({'id':DATA_GENERATION})\n",
    "    datageneration.GetContentFile(DATA_GENERATION_FILE)\n",
    "\n",
    "    helpers = drive.CreateFile({'id':HELPERS})\n",
    "    helpers.GetContentFile(HELPERS_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aviCJYdobf2t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU\n"
     ]
    }
   ],
   "source": [
    "# checking whether CUDA is available \n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgX31aWtVX9P",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# pytorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import softplus\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "\n",
    "# general helpers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import os\n",
    "import json\n",
    "# custom imports\n",
    "\n",
    "from datageneration import DataGenerator\n",
    "from helpers import Helper\n",
    "from networs import Encoder, Decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4_opgenVX9S",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Workflow of the implementation\n",
    "\n",
    "- CNPS as Gaussian Processes try to learn a distribution over the functional value vector $V=(f(x_1).....f(x_n))$\n",
    "- At test time any function from this distribution can be approximated\n",
    "- The function will take into consideration the context points that have beeen give to make one function from this distribution more likely than others.\n",
    "\n",
    "### Data Generation:\n",
    "- The training points come from various functions that share some common characteristic\n",
    "- In this implemenation the different functions come from __one__ Gaussian process\n",
    "- A GP is a multivariate normal distribution, aka a mean and covariance matrix, where each dimension of the infinite random vector is a, aka random variable, is the functional value for a given input value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tnky-Z5UVX9S"
   },
   "source": [
    "1. The Kernel - __Creates a covariance matrix__: A function that takes in x values and returns a co-variance matrix. Here the Gaussian Kernel, RBF, or squared exponential is used. It computes the differences between all one dimensional feature vectors scales this distance by ``l``, squares it and scales it again by ``sigma_f``. As seen in other implementations (<a href = https://www.inf.ed.ac.uk/teaching/courses/mlpr/2019/notes/gp_minimal.py> GP demo</a>) some noises is added to the diagonal or to the variance of the covariance matrix to ensure a positive definite matrix and thus allow the Cholesky decomposition to be defined.\n",
    "<br><br>\n",
    "2. Curve Generator - __Generates functions from a GP__: We first set ``num_context_points`` <br>\n",
    "__Training__: The number of target points is a random share of the context points. Random ``x_values`` are generated from a ``uniform`` between `-2` and `2`. Each of the ``batch_size`` vectors of context points is 1 by ``num_context_points``.<br>\n",
    "__Testing__:For testing more ``targets`` (400) are created and are simply set at ``0.001`` intervals between `-2` and `2`.  <br><br>\n",
    "The Kernel scale parameters are set and the ``x_values`` are past through the ``kernel`` to create the covariance matrix. The covariance matrix is decomposed with the ``cholesky``decomposition. The ``y_values`` are created through the following process:\n",
    "Given the standardization of a non-standard multivariate normal $Z=\\frac{X-\\mu}{\\sigma}$ we can create the non-standard multivariate normal by $L^-1*Z+\\mu=Z$ where $L^-1$ is the Cholesky.\n",
    "\n",
    "Finally, depending on training/ testing the appropriate number of points are selected from the ``x_values`` and the ``y_values``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wz5T4ZPTVX9T"
   },
   "source": [
    "### Training, predicting with GPs:\n",
    "\n",
    "GPs during training build the posterior distribution conditioned on the observed data.\n",
    "At test time this distribution serves as the prior which will then be updated using the Bayes rule. Drawing from this distribution or taking the expected value is the prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VAxnhmmeVX9T"
   },
   "source": [
    "## Covariance Function for Gaussian Process:\n",
    "- The Covariance function encodes our believes about the function to be generated/ learned \n",
    "- It encodes notion of similarity, i.e. similar inputs produce similar outputs\n",
    "- Different factors influence the choice of the covariance function\n",
    "- __Stationary covariance__ function is invariant to translations on the input space\n",
    " - I guess this it is constant when the inputs are transformed \n",
    "- __Isotropy or isotropic__ covariance functions are functions only of $|X_1-X_2|$, i.e. $K(X_1,X_2)$.\n",
    "- The function only depends on the distance between the two input vectors\n",
    "- This implementation uses the squared expnential, aka Radial Basis Function aka Gaussian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Uh33yfUVX9U"
   },
   "source": [
    "## Generating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('config.json') as f:\n",
    "    file = f.read()\n",
    "    conf = json.loads(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rr0dyyQ6VX9U",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "datagenerator = DataGenerator(**conf['default']['data_gen_params'])\n",
    "x_values, func_x = datagenerator.generate_curves()\n",
    "func_x = Helper.list_np_to_sensor(func_x)\n",
    "x_values = x_values.repeat(func_x.shape[0], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nc62cRrNVX9W"
   },
   "outputs": [],
   "source": [
    "train_len = int(x_values.shape[0] * conf['default']['train_share'])\n",
    "traindata = data.TensorDataset(x_values[:train_len], func_x[:train_len])\n",
    "trainloader = data.DataLoader(traindata, batch_size=10)\n",
    "validata = data.TensorDataset(x_values[train_len:], func_x[train_len:])\n",
    "valiloader = data.DataLoader(validata, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "loDhgZHcVX9e"
   },
   "source": [
    "## Encoder\n",
    "\n",
    "The encoder creates a representation of the data context data. Some technicalilites to understand are the following: \n",
    "- The encoder simply takes a concatenation of the x,y values\n",
    "- x values are of shape batch_size*number of context points, dimx\n",
    "- y values are of shape batch_size*number of context points, 1\n",
    "- the represenation ri can be of the dimensions that we choose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwhCM9UpVX9e",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    \n",
    "    \"\"\"This class maps each x_i, y_i context point to a representation r_i\n",
    "    To learn this Representation we are using a Multi Layer Perceptron\n",
    "    The input shape will be batch_size, num_context_points, x_dim\n",
    "    \n",
    "    The input to the encoder are the value pairs, thus the dimensions are \n",
    "    Batch_Size, (dimx+dimy). The Pytorch automatically pases the values sequentially\n",
    "    through the ANN.\n",
    "    The last layer will not have an activation function because we want the pure represenation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    dimx : int\n",
    "        Dimesion of each x value\n",
    "    \n",
    "    dimy : int\n",
    "        Dimesion of each y value\n",
    "        \n",
    "    dimr : int\n",
    "        Dimension of output representation\n",
    "    \n",
    "    dimh : tuple\n",
    "        Dimension of hidden layers\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, dimx, dimy, dimr, dimh):\n",
    "        super().__init__()\n",
    "            \n",
    "        self._dimx = dimx\n",
    "        self._dimy = dimy\n",
    "        self._dimr = dimr\n",
    "        self._dimh = dimh\n",
    "        \n",
    "        \n",
    "        _first_layer = [nn.Linear(self._dimx+self._dimy, self._dimh[0]),nn.ReLU()]\n",
    "        \n",
    "        \n",
    "        _hidden_layers = list(np.array([\n",
    "            [nn.Linear(self._dimh[i], self._dimh[i+1]),nn.ReLU()]\n",
    "            for i in range(len(self._dimh)-2)\n",
    "        ]).flatten())\n",
    "        \n",
    "        _last_layer = [nn.Linear(self._dimh[-2], self._dimh[-1])]\n",
    "        \n",
    "        self._layers = _first_layer + _hidden_layers + _last_layer\n",
    "        \n",
    "        \n",
    "        self._process_input = nn.Sequential(*self._layers)\n",
    "    def forward(self, x_values, y_values):\n",
    "        \"\"\"\n",
    "        Takes the context points x and y,\n",
    "        concatenates them into value pairs\n",
    "        and passes them through the MLP\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        x_values : torch.Tensor \n",
    "            Shape (batch_size, dimx)\n",
    "            \n",
    "        y_values : torch.Tensor \n",
    "            Shape (batch_size, dimy)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        input_as_pairs = torch.cat((x_values, y_values), dim=1)\n",
    "\n",
    "    \n",
    "        return self._process_input(input_as_pairs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xv6d1gRRVX9h"
   },
   "source": [
    "## Aggregator\n",
    "\n",
    "- The aggregator simply creates an aggregation'\n",
    "- Here we simply take the average of ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2hwhhiTkVX9h",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def aggregate(ri_tensor):\n",
    "    \"\"\"Takes a tensor of shape (batch_size,num_context_points, dimr) and aggregates it a\n",
    "    along the second axis so that we have an aggregation across each batch\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    ri_tensor : Tensor\n",
    "        Tensor of the representation of the x and y context points\n",
    "    \"\"\"\n",
    "    \n",
    "    return ri_tensor.mean(dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KhA0RDRlVX9j"
   },
   "source": [
    "## Decoder\n",
    "\n",
    "- The decoder takes the context points and the representation, passes them through an MLP and returns an output of dimensions two\n",
    "- These two are used to minimize the negative log conditinal ligelihood which is a function that depends on the mu and sigma\n",
    "- By minimize this quantitiy we find the correct parameters to the distribution of the Gaussian process from which the context points were drawn.\n",
    "- We need to get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiiIO5NvVX9k",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    \"\"\"The decoder takes in x_values, that is the target points and combines them with\n",
    "    the represenation of the context points by concatenation. The resulting tensor is passed to an MLP that \n",
    "    is asked to ouput the parameters for the sought after distribution, in this case\n",
    "    a normal distribution. Thus we are looking for two parameters. The MLP returns two tensor obejects\n",
    "    which hold a mean/ variance for each point y. Thus the shape of this output is \n",
    "    batch_size,y_values,y_dim, 2\n",
    "    \n",
    "    Note the targets consist\n",
    "    of both the context points as well as the target points, since the context points\n",
    "    are a subset of the target points.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        \n",
    "    dimx : int\n",
    "        Dimension of each x value\n",
    "    \n",
    "    dimr : int\n",
    "        Dimension of each of the representations\n",
    "    \n",
    "    *args : tuple\n",
    "        Dimensions of the hidden layers \n",
    "             \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,dimx, dimr,dimparam,dimh):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self._dimx = dimx\n",
    "        self._dimr = dimr\n",
    "        self._dimparam = dimparam\n",
    "        self._dimh = dimh\n",
    "        \n",
    "        _first_layer = [nn.Linear(self._dimx+self._dimr, self._dimh[0]),nn.ReLU()]\n",
    "        \n",
    "        _hidden_layers = list(np.array([\n",
    "            [nn.Linear(self._dimh[i], self._dimh[i+1]),nn.ReLU()]\n",
    "            for i in range(len(self._dimh)-1)\n",
    "        ]).flatten())\n",
    "        \n",
    "        _last_layer = [nn.Linear(self._dimh[-1], self._dimparam)]\n",
    "        \n",
    "        self._layers = _first_layer + _hidden_layers + _last_layer\n",
    "        \n",
    "        \n",
    "        self._process_input = nn.Sequential(*self._layers)\n",
    "        \n",
    "    def forward(self, x_values,r_values):\n",
    "        \n",
    "        \"\"\"Takes x and r values, combines them and passes them twice to MLP. \n",
    "        Thus we have one run for mu and one run for sigma\"\"\"\n",
    "        \n",
    "        input_as_pairs = torch.cat((x_values, r_values),dim=1)\n",
    "        \n",
    "        dist_params = self._process_input(input_as_pairs)\n",
    "        return self._process_input(input_as_pairs)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "daIo3GePVX9m"
   },
   "outputs": [],
   "source": [
    "def transform_var(var_tensor):\n",
    "    \n",
    "    '''This function takes a learned variance tensor and transforms \n",
    "    it following the methodology in Empirical Evaluation of Neural Process Objectives.\n",
    "    This ensures that the covariance matrix is positive definite and a multivariate\n",
    "    Gaussian can be constructed.\n",
    "    Next it pads the diagonal with zeroes to create a covariance matrix for sampling.\n",
    "   '''\n",
    "    transformed_variance =  0.1+0.9*softplus(var_tensor)\n",
    "    cov_matrix = torch.diag_embed(transformed_variance)\n",
    "    return cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1j58G8OVX9r"
   },
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n_epochs,\n",
    "                 lr,\n",
    "                 max_funcs,\n",
    "                 max_contx,\n",
    "                 min_contx,\n",
    "                 dim_observation,\n",
    "                 dimx=1,\n",
    "                 dimy=1,\n",
    "                 dimr=50,\n",
    "                 dimout=2,\n",
    "                 dim_encoder=[128,128,128],\n",
    "                 dim_decoder=[128,128,128],\n",
    "                 train_on_gpu=False,\n",
    "                 print_after=100):\n",
    "        super().__init__()\n",
    "    \n",
    "        self._n_epochs = n_epochs\n",
    "        self._lr = lr\n",
    "        self._max_trgts = max_funcs\n",
    "        self._max_contx = max_contx\n",
    "        self._min_contx = min_contx\n",
    "        self._dim_observation = dim_observation\n",
    "        self._dimx = dimx\n",
    "        self._dimy = dimy\n",
    "        self._dimr = dimr\n",
    "        self._dimout = dimout\n",
    "        self._dim_encoder = dim_encoder\n",
    "        self._dim_decoder = dim_decoder\n",
    "        self.train_on_gpu = train_on_gpu\n",
    "        self._print_after = print_after\n",
    "    \n",
    "    def _get_sample_indexes(self, both=True):\n",
    "        num_contxt = np.random.randint(self._min_contx, self._max_contx)\n",
    "        num_trgts = np.random.randint(self._max_contx,self._max_trgts)  \n",
    "        trgts_idx = np.random.choice(np.arange(0,self._dim_observation), num_trgts)\n",
    "        contxt_idx = trgts_idx[:num_contxt]\n",
    "        if both:\n",
    "            return trgts_idx, contxt_idx\n",
    "        else:\n",
    "            return contxt_idx\n",
    "        \n",
    "        \n",
    "    def _validation_run(self, valiloader, encoder, decoder, current_epoch):\n",
    "        \n",
    "        encoder.eval()\n",
    "        encoder.eval()\n",
    "        \n",
    "        running_vali_loss = 0\n",
    "        self.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for xvalues, funcvalues in valiloader:\n",
    "                if self.train_on_gpu:\n",
    "                    xvalues, funcvalues = xvalues.cuda(), funcvalues.cuda()\n",
    "                \n",
    "                batch_size = xvalues.shape[0]\n",
    "\n",
    "                target_y = funcvalues[:,:,:]\n",
    "                target_x = xvalues[:,:,:]\n",
    "                \n",
    "                contxt_idx = self._get_sample_indexes(both=False)\n",
    "                num_contxt,num_trgt = len(contxt_idx),self._dim_observation\n",
    "                \n",
    "\n",
    "                context_y = funcvalues[:,contxt_idx,:]\n",
    "                context_x = xvalues[:,contxt_idx,:]\n",
    "\n",
    "                # the encoding is stacked to ensure a one dimensional input\n",
    "                context_y_stacked = context_y.view(batch_size*num_contxt,-1)\n",
    "                context_x_stacked = context_x.view(batch_size*num_contxt,-1)\n",
    "                            \n",
    "                                # running the context values through the encoding\n",
    "                encoding  = encoder(context_x_stacked,context_y_stacked)\n",
    "                encoding  = encoding.view(batch_size,num_contxt,-1)\n",
    "                            # averaging the encoding \n",
    "                encoding_avg  = encoding.mean(1)\n",
    "                # we need to unsqueeze and repeat the embedding\n",
    "                # because we need to pair it with every target\n",
    "                encoding_avg  = encoding_avg.unsqueeze(1)\n",
    "                encoding_exp  = encoding_avg.repeat(1,num_trgt,1)\n",
    "\n",
    "                encoding_stacked = encoding_exp.view(batch_size*num_trgt,-1)\n",
    "                target_x_stacked = target_x.view(batch_size*num_trgt,-1)\n",
    "\n",
    "                decoding = decoder(target_x_stacked,encoding_stacked)\n",
    "                decoding_rshp = decoding.view(batch_size,num_trgt,-1)\n",
    "\n",
    "\n",
    "                mu,sigma = decoding_rshp[:,:,0], decoding_rshp[:,:,1]\n",
    "                cov_matrix = Helper.transform_var(sigma)    \n",
    "                distribution = MultivariateNormal(loc=mu, covariance_matrix=cov_matrix)\n",
    "                \n",
    "                vali_loss = distribution.log_prob(target_y.squeeze(-1))\n",
    "                vali_loss = -torch.mean(vali_loss)\n",
    "                running_vali_loss += vali_loss.item()\n",
    "            else:\n",
    "                print(f' Validation loss after {current_epoch} equals {running_vali_loss/(len(valiloader))}')\n",
    "                \n",
    "                                                                            \n",
    "    def run_training(self, trainloader, valiloader=None):\n",
    "        # defining the Encoder and the Decoder nstances\n",
    "        encoder = Encoder(self._dimx, self._dimy, self._dimr, self._dim_encoder)\n",
    "        decoder = Decoder(self._dimx, self._dim_encoder[-1], self._dimout, self._dim_decoder)\n",
    "        \n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        \n",
    "        if self.train_on_gpu:\n",
    "            xvalues, funcvalues = xvalues.cuda(), funcvalues.cuda()\n",
    "\n",
    "\n",
    "        optimizer = optim.Adam(decoder.parameters())\n",
    "        mean_epoch_loss = []\n",
    "        \n",
    "        for epoch in range(self._n_epochs):\n",
    "            running_loss = 0\n",
    "#         get sample indexes\n",
    "            for xvalues, funcvalues in trainloader:\n",
    "                if self.train_on_gpu:\n",
    "                    xvalues, funcvalues = xvalues.cuda(), funcvalues.cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "#               we sample for every single batch  \n",
    "#               Setting the batch size here is not ideal\n",
    "                batch_size = xvalues.shape[0]\n",
    "            \n",
    "                func_idx, contxt_idx = self._get_sample_indexes()\n",
    "                num_trgt,num_contxt = len(func_idx),len(contxt_idx)\n",
    "                \n",
    "                target_y = funcvalues[:,func_idx,:]\n",
    "                target_x = xvalues[:,func_idx,:]\n",
    "                \n",
    "                context_y = funcvalues[:,contxt_idx,:]\n",
    "                context_x = xvalues[:,contxt_idx,:]\n",
    "                \n",
    "                \n",
    "                # the encoding is stacked to ensure a one dimensional input\n",
    "                context_y_stacked = context_y.view(batch_size*num_contxt,-1)\n",
    "                context_x_stacked = context_x.view(batch_size*num_contxt,-1)\n",
    "\n",
    "                # running the context values through the encoding\n",
    "                encoding  = encoder(context_x_stacked, context_y_stacked)\n",
    "                encoding  = encoding.view(batch_size, num_contxt,-1)\n",
    "                # averaging the encoding \n",
    "                encoding_avg  = encoding.mean(1)\n",
    "                # we need to unsqueeze and repeat the embedding\n",
    "                # because we need to pair it with every target\n",
    "                encoding_avg  = encoding_avg.unsqueeze(1)\n",
    "                encoding_exp  = encoding_avg.repeat(1,num_trgt,1)\n",
    "\n",
    "                encoding_stacked = encoding_exp.view(batch_size*num_trgt,-1)\n",
    "                target_x_stacked = target_x.view(batch_size*num_trgt,-1)\n",
    "                \n",
    "                decoding = decoder(target_x_stacked,encoding_stacked)\n",
    "                decoding_rshp = decoding.view(batch_size,num_trgt,-1)\n",
    "                \n",
    "#              \n",
    "                mu,sigma = decoding_rshp[:,:,0], decoding_rshp[:,:,1]\n",
    "                \n",
    "                \n",
    "                cov_matrix = Helper.transform_var(sigma)    \n",
    "                distribution = MultivariateNormal(loc=mu, covariance_matrix=cov_matrix)\n",
    "\n",
    "                loss = distribution.log_prob(target_y.squeeze(-1))\n",
    "                loss = -torch.mean(loss)\n",
    "                running_loss += loss\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                mean_epoch_loss.append(running_loss/len(trainloader))\n",
    "                \n",
    "                if epoch%self._print_after==0 and epoch>0 :\n",
    "                    print(f'Mean loss at epoch {epoch} : {mean_epoch_loss[-1]}')\n",
    "                    if valiloader:\n",
    "                        self._validation_run(valiloader, encoder, decoder, epoch)\n",
    "                        encoder.train(), decoder.train()\n",
    "                        \n",
    "\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(**conf['default']['train_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Herzps7VVX91",
    "outputId": "f4b73fb0-a292-4e6a-8f4d-95fde9056e71",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss at epoch 100 : 4.510929107666016\n",
      " Validation loss after 100 equals 718.4684448242188\n",
      "Mean loss at epoch 200 : 4.1975202560424805\n",
      " Validation loss after 200 equals 657.4709777832031\n",
      "Mean loss at epoch 300 : 3.870605230331421\n",
      " Validation loss after 300 equals 963.8392639160156\n",
      "Mean loss at epoch 400 : 3.583146095275879\n",
      " Validation loss after 400 equals 593.177734375\n",
      "Mean loss at epoch 500 : 3.7492432594299316\n",
      " Validation loss after 500 equals 550.8181457519531\n",
      "Mean loss at epoch 600 : 3.4174060821533203\n",
      " Validation loss after 600 equals 667.5623779296875\n",
      "Mean loss at epoch 700 : 3.575927734375\n",
      " Validation loss after 700 equals 590.6448059082031\n",
      "Mean loss at epoch 800 : 3.413320541381836\n",
      " Validation loss after 800 equals 747.7361755371094\n",
      "Mean loss at epoch 900 : 3.564199447631836\n",
      " Validation loss after 900 equals 1092.1128540039062\n",
      "Mean loss at epoch 1000 : 3.412710666656494\n",
      " Validation loss after 1000 equals 656.3455810546875\n",
      "Mean loss at epoch 1100 : 3.3485426902770996\n",
      " Validation loss after 1100 equals 526.9195098876953\n",
      "Mean loss at epoch 1200 : 3.1249001026153564\n",
      " Validation loss after 1200 equals 796.9879150390625\n",
      "Mean loss at epoch 1300 : 3.115215539932251\n",
      " Validation loss after 1300 equals 766.3860168457031\n",
      "Mean loss at epoch 1400 : 3.253086566925049\n",
      " Validation loss after 1400 equals 617.2296905517578\n",
      "Mean loss at epoch 1500 : 3.175471782684326\n",
      " Validation loss after 1500 equals 626.3372192382812\n",
      "Mean loss at epoch 1600 : 3.2307677268981934\n",
      " Validation loss after 1600 equals 550.0006103515625\n",
      "Mean loss at epoch 1700 : 3.2611234188079834\n",
      " Validation loss after 1700 equals 313.6619415283203\n",
      "Mean loss at epoch 1800 : 3.0071001052856445\n",
      " Validation loss after 1800 equals 513.6881256103516\n",
      "Mean loss at epoch 1900 : 3.0660147666931152\n",
      " Validation loss after 1900 equals 855.4268798828125\n",
      "Mean loss at epoch 2000 : 3.200963020324707\n",
      " Validation loss after 2000 equals 453.6358947753906\n",
      "Mean loss at epoch 2100 : 3.338073492050171\n",
      " Validation loss after 2100 equals 621.1902465820312\n",
      "Mean loss at epoch 2200 : 3.08707332611084\n",
      " Validation loss after 2200 equals 564.6040649414062\n",
      "Mean loss at epoch 2300 : 3.175712823867798\n",
      " Validation loss after 2300 equals 662.1807250976562\n",
      "Mean loss at epoch 2400 : 3.0787813663482666\n",
      " Validation loss after 2400 equals 391.90269470214844\n",
      "Mean loss at epoch 2500 : 3.1834585666656494\n",
      " Validation loss after 2500 equals 722.1331787109375\n",
      "Mean loss at epoch 2600 : 3.1172263622283936\n",
      " Validation loss after 2600 equals 524.1403656005859\n",
      "Mean loss at epoch 2700 : 3.070255756378174\n",
      " Validation loss after 2700 equals 443.29981994628906\n",
      "Mean loss at epoch 2800 : 3.2751171588897705\n",
      " Validation loss after 2800 equals 940.2254638671875\n",
      "Mean loss at epoch 2900 : 2.980452299118042\n",
      " Validation loss after 2900 equals 672.2164001464844\n",
      "Mean loss at epoch 3000 : 2.991311550140381\n",
      " Validation loss after 3000 equals 563.0484313964844\n",
      "Mean loss at epoch 3100 : 2.9596433639526367\n",
      " Validation loss after 3100 equals 513.8434600830078\n",
      "Mean loss at epoch 3200 : 3.3440990447998047\n",
      " Validation loss after 3200 equals 594.7352142333984\n",
      "Mean loss at epoch 3300 : 2.975632429122925\n",
      " Validation loss after 3300 equals 992.06787109375\n",
      "Mean loss at epoch 3400 : 2.9026620388031006\n",
      " Validation loss after 3400 equals 675.3700561523438\n",
      "Mean loss at epoch 3500 : 2.961587905883789\n",
      " Validation loss after 3500 equals 455.0115966796875\n",
      "Mean loss at epoch 3600 : 3.145357131958008\n",
      " Validation loss after 3600 equals 557.4869689941406\n",
      "Mean loss at epoch 3700 : 3.0641262531280518\n",
      " Validation loss after 3700 equals 765.3540954589844\n",
      "Mean loss at epoch 3800 : 2.912107229232788\n",
      " Validation loss after 3800 equals 676.1080322265625\n",
      "Mean loss at epoch 3900 : 3.4051928520202637\n",
      " Validation loss after 3900 equals 756.3079833984375\n",
      "Mean loss at epoch 4000 : 2.9401986598968506\n",
      " Validation loss after 4000 equals 465.237548828125\n",
      "Mean loss at epoch 4100 : 3.0217905044555664\n",
      " Validation loss after 4100 equals 383.144287109375\n",
      "Mean loss at epoch 4200 : 2.904946804046631\n",
      " Validation loss after 4200 equals 523.3322906494141\n",
      "Mean loss at epoch 4300 : 3.016908884048462\n",
      " Validation loss after 4300 equals 558.6818542480469\n",
      "Mean loss at epoch 4400 : 2.9712073802948\n",
      " Validation loss after 4400 equals 550.4996337890625\n",
      "Mean loss at epoch 4500 : 2.8655991554260254\n",
      " Validation loss after 4500 equals 548.0914154052734\n",
      "Mean loss at epoch 4600 : 3.0757689476013184\n",
      " Validation loss after 4600 equals 664.3868103027344\n",
      "Mean loss at epoch 4700 : 2.8834304809570312\n",
      " Validation loss after 4700 equals 674.7597961425781\n",
      "Mean loss at epoch 4800 : 2.9334824085235596\n",
      " Validation loss after 4800 equals 725.9973602294922\n",
      "Mean loss at epoch 4900 : 2.8653955459594727\n",
      " Validation loss after 4900 equals 535.3992614746094\n",
      "Mean loss at epoch 5000 : 2.968066692352295\n",
      " Validation loss after 5000 equals 690.1837768554688\n",
      "Mean loss at epoch 5100 : 2.844454765319824\n",
      " Validation loss after 5100 equals 439.87054443359375\n",
      "Mean loss at epoch 5200 : 2.8411004543304443\n",
      " Validation loss after 5200 equals 606.4747619628906\n",
      "Mean loss at epoch 5300 : 3.0666425228118896\n",
      " Validation loss after 5300 equals 491.21734619140625\n",
      "Mean loss at epoch 5400 : 3.1604065895080566\n",
      " Validation loss after 5400 equals 596.4525146484375\n",
      "Mean loss at epoch 5500 : 2.8555350303649902\n",
      " Validation loss after 5500 equals 681.3144226074219\n",
      "Mean loss at epoch 5600 : 2.902784824371338\n",
      " Validation loss after 5600 equals 605.3962097167969\n",
      "Mean loss at epoch 5700 : 2.9642345905303955\n",
      " Validation loss after 5700 equals 518.7977600097656\n",
      "Mean loss at epoch 5800 : 3.117708206176758\n",
      " Validation loss after 5800 equals 451.34327697753906\n",
      "Mean loss at epoch 5900 : 2.9738528728485107\n",
      " Validation loss after 5900 equals 702.0242614746094\n",
      "Mean loss at epoch 6000 : 3.0148301124572754\n",
      " Validation loss after 6000 equals 948.1006469726562\n",
      "Mean loss at epoch 6100 : 3.020378828048706\n",
      " Validation loss after 6100 equals 518.7386169433594\n",
      "Mean loss at epoch 6200 : 2.636793851852417\n",
      " Validation loss after 6200 equals 375.6026306152344\n",
      "Mean loss at epoch 6300 : 2.759662389755249\n",
      " Validation loss after 6300 equals 527.0824279785156\n",
      "Mean loss at epoch 6400 : 2.8329131603240967\n",
      " Validation loss after 6400 equals 668.2117004394531\n",
      "Mean loss at epoch 6500 : 2.881093978881836\n",
      " Validation loss after 6500 equals 489.20823669433594\n",
      "Mean loss at epoch 6600 : 2.95585560798645\n",
      " Validation loss after 6600 equals 613.579345703125\n",
      "Mean loss at epoch 6700 : 2.9635379314422607\n",
      " Validation loss after 6700 equals 484.6862487792969\n",
      "Mean loss at epoch 6800 : 2.8807497024536133\n",
      " Validation loss after 6800 equals 755.2891845703125\n",
      "Mean loss at epoch 6900 : 2.843278408050537\n",
      " Validation loss after 6900 equals 673.5290222167969\n",
      "Mean loss at epoch 7000 : 2.940680503845215\n",
      " Validation loss after 7000 equals 531.3316650390625\n",
      "Mean loss at epoch 7100 : 2.901341438293457\n",
      " Validation loss after 7100 equals 843.0616149902344\n",
      "Mean loss at epoch 7200 : 2.9670848846435547\n",
      " Validation loss after 7200 equals 395.523193359375\n",
      "Mean loss at epoch 7300 : 2.9984307289123535\n",
      " Validation loss after 7300 equals 801.22607421875\n",
      "Mean loss at epoch 7400 : 3.0253469944000244\n",
      " Validation loss after 7400 equals 577.4687805175781\n",
      "Mean loss at epoch 7500 : 2.858762264251709\n",
      " Validation loss after 7500 equals 572.3129272460938\n",
      "Mean loss at epoch 7600 : 2.783031702041626\n",
      " Validation loss after 7600 equals 609.3497314453125\n",
      "Mean loss at epoch 7700 : 2.8210926055908203\n",
      " Validation loss after 7700 equals 505.4306640625\n",
      "Mean loss at epoch 7800 : 3.016435146331787\n",
      " Validation loss after 7800 equals 506.0998992919922\n",
      "Mean loss at epoch 7900 : 2.8033673763275146\n",
      " Validation loss after 7900 equals 549.3272094726562\n",
      "Mean loss at epoch 8000 : 2.8526101112365723\n",
      " Validation loss after 8000 equals 632.3898620605469\n",
      "Mean loss at epoch 8100 : 2.823312997817993\n",
      " Validation loss after 8100 equals 821.031494140625\n",
      "Mean loss at epoch 8200 : 2.9399032592773438\n",
      " Validation loss after 8200 equals 638.7258605957031\n",
      "Mean loss at epoch 8300 : 2.7451906204223633\n",
      " Validation loss after 8300 equals 385.4872283935547\n",
      "Mean loss at epoch 8400 : 2.9484975337982178\n",
      " Validation loss after 8400 equals 613.3694763183594\n",
      "Mean loss at epoch 8500 : 2.916508436203003\n",
      " Validation loss after 8500 equals 451.080078125\n"
     ]
    }
   ],
   "source": [
    "weights = trainer.run_training(trainloader,valiloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xCGZFQEPVX97",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " ## Sandbox - testing the individual parts of the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zq7EjYIjVX97",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Kernel function\n",
    "Expanding the dimesions of the tensors allows us substract each point pairwise\n",
    "This being a 1-D use case we simply substract each of the data points and get an n by n matrix for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddwlABKhVX98",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_points = 10\n",
    "dimx = 1\n",
    "dimy = 1\n",
    "rdim = 20\n",
    "hdim = 20\n",
    "x = Helper.scale_shift_uniform(-2,2,batch_size,num_points,dimx)\n",
    "y = Helper.scale_shift_uniform(-2,2,batch_size,num_points,dimy)\n",
    "\n",
    "x_stacked  = x.view(batch_size*num_points,-1)\n",
    "y_stacked  = y.view(batch_size*num_points,-1)\n",
    "encoder = Encoder(1,1,hdim,[hdim,hdim,rdim])\n",
    "r  = encoder.forward(x_stacked,y_stacked)\n",
    "r = r.view(batch_size,num_points,-1)\n",
    "r_aggregate = aggregate(r).unsqueeze(1)\n",
    "print(r_aggregate.shape)\n",
    "r_aggregate = r_aggregate.repeat(1,num_points,1)\n",
    "print(r_aggregate.shape)\n",
    "\n",
    "hdim = 128\n",
    "outdim = 2\n",
    "decoder = Decoder(dimx,rdim,outdim,[hdim,hdim,hdim])\n",
    "\n",
    "r_stacked = r_aggregate.view(batch_size*num_points,-1)\n",
    "print(r_stacked.shape)\n",
    "dist_params = decoder.forward(x_stacked, r_stacked).view(batch_size,num_points,-1)\n",
    "\n",
    "mu = dist_params[:,:,0]\n",
    "sigma = torch.diag_embed(dist_params[:,:,1])\n",
    "sigma_test = torch.ones(10).unsqueeze(0).repeat(64,1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "conditional_neural_process_pytorch_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
