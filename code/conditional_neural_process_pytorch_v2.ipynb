{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# pytorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import softplus\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "\n",
    "# general helpers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "# custom imports\n",
    "\n",
    "from datageneration import DataGenerator\n",
    "from helpers import Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Workflow of the implementation\n",
    "\n",
    "- CNPS as Gaussian Processes try to learn a distribution over the functional value vector $V=(f(x_1).....f(x_n))$\n",
    "- At test time any function from this distribution can be approximated\n",
    "- The function will take into consideration the context points that have beeen give to make one function from this distribution more likely than others.\n",
    "\n",
    "### Data Generation:\n",
    "- The training points come from various functions that share some common characteristic\n",
    "- In this implemenation the different functions come from __one__ Gaussian process\n",
    "- A GP is a multivariate normal distribution, aka a mean and covariance matrix, where each dimension of the infinite random vector is a, aka random variable, is the functional value for a given input value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The Kernel - __Creates a covariance matrix__: A function that takes in x values and returns a co-variance matrix. Here the Gaussian Kernel, RBF, or squared exponential is used. It computes the differences between all one dimensional feature vectors scales this distance by ``l``, squares it and scales it again by ``sigma_f``. As seen in other implementations (<a href = https://www.inf.ed.ac.uk/teaching/courses/mlpr/2019/notes/gp_minimal.py> GP demo</a>) some noises is added to the diagonal or to the variance of the covariance matrix to ensure a positive definite matrix and thus allow the Cholesky decomposition to be defined.\n",
    "<br><br>\n",
    "2. Curve Generator - __Generates functions from a GP__: We first set ``num_context_points`` <br>\n",
    "__Training__: The number of target points is a random share of the context points. Random ``x_values`` are generated from a ``uniform`` between `-2` and `2`. Each of the ``batch_size`` vectors of context points is 1 by ``num_context_points``.<br>\n",
    "__Testing__:For testing more ``targets`` (400) are created and are simply set at ``0.001`` intervals between `-2` and `2`.  <br><br>\n",
    "The Kernel scale parameters are set and the ``x_values`` are past through the ``kernel`` to create the covariance matrix. The covariance matrix is decomposed with the ``cholesky``decomposition. The ``y_values`` are created through the following process:\n",
    "Given the standardization of a non-standard multivariate normal $Z=\\frac{X-\\mu}{\\sigma}$ we can create the non-standard multivariate normal by $L^-1*Z+\\mu=Z$ where $L^-1$ is the Cholesky.\n",
    "\n",
    "Finally, depending on training/ testing the appropriate number of points are selected from the ``x_values`` and the ``y_values``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, predicting with GPs:\n",
    "\n",
    "GPs during training build the posterior distribution conditioned on the observed data.\n",
    "At test time this distribution serves as the prior which will then be updated using the Bayes rule. Drawing from this distribution or taking the expected value is the prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance Function for Gaussian Process:\n",
    "- The Covariance function encodes our believes about the function to be generated/ learned \n",
    "- It encodes notion of similarity, i.e. similar inputs produce similar outputs\n",
    "- Different factors influence the choice of the covariance function\n",
    "- __Stationary covariance__ function is invariant to translations on the input space\n",
    " - I guess this it is constant when the inputs are transformed \n",
    "- __Isotropy or isotropic__ covariance functions are functions only of $|X_1-X_2|$, i.e. $K(X_1,X_2)$.\n",
    "- The function only depends on the distance between the two input vectors\n",
    "- This implementation uses the squared expnential, aka Radial Basis Function aka Gaussian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "datagenerator = DataGenerator(xdim=1,ydim=1,num_instances=640, range_x=(-2,2),steps=500)\n",
    "x_values,func_x = datagenerator.generate_curves()\n",
    "func_x = Helper.list_np_to_sensor(func_x)\n",
    "x_values = x_values.repeat(func_x.shape[0],1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "one_d_dataset = data.TensorDataset(x_values, func_x)\n",
    "one_d_dataloader = data.DataLoader(one_d_dataset,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "The encoder creates a representation of the data context data. Some technicalilites to understand are the following: \n",
    "- The encoder simply takes a concatenation of the x,y values\n",
    "- x values are of shape batch_size*number of context points, dimx\n",
    "- y values are of shape batch_size*number of context points, 1\n",
    "- the represenation ri can be of the dimensions that we choose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    \n",
    "    \"\"\"This class maps each x_i, y_i context point to a representation r_i\n",
    "    To learn this Representation we are using a Multi Layer Perceptron\n",
    "    The input shape will be batch_size, num_context_points, x_dim\n",
    "    \n",
    "    The input to the encoder are the value pairs, thus the dimensions are \n",
    "    Batch_Size, (dimx+dimy). The Pytorch automatically pases the values sequentially\n",
    "    through the ANN.\n",
    "    The last layer will not have an activation function because we want the pure represenation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    dimx : int\n",
    "        Dimesion of each x value\n",
    "    \n",
    "    dimy : int\n",
    "        Dimesion of each y value\n",
    "        \n",
    "    dimr : int\n",
    "        Dimension of output representation\n",
    "    \n",
    "    dimh : tuple\n",
    "        Dimension of hidden layers\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, dimx, dimy, dimr, dimh):\n",
    "        super().__init__()\n",
    "            \n",
    "        self._dimx = dimx\n",
    "        self._dimy = dimy\n",
    "        self._dimr = dimr\n",
    "        self._dimh = dimh\n",
    "        \n",
    "        \n",
    "        _first_layer = [nn.Linear(self._dimx+self._dimy, self._dimh[0]),nn.ReLU()]\n",
    "        \n",
    "        \n",
    "        _hidden_layers = list(np.array([\n",
    "            [nn.Linear(self._dimh[i], self._dimh[i+1]),nn.ReLU()]\n",
    "            for i in range(len(self._dimh)-2)\n",
    "        ]).flatten())\n",
    "        \n",
    "        _last_layer = [nn.Linear(self._dimh[-2], self._dimh[-1])]\n",
    "        \n",
    "        self._layers = _first_layer + _hidden_layers + _last_layer\n",
    "        \n",
    "        \n",
    "        self._process_input = nn.Sequential(*self._layers)\n",
    "    def forward(self, x_values, y_values):\n",
    "        \"\"\"\n",
    "        Takes the context points x and y,\n",
    "        concatenates them into value pairs\n",
    "        and passes them through the MLP\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        x_values : torch.Tensor \n",
    "            Shape (batch_size, dimx)\n",
    "            \n",
    "        y_values : torch.Tensor \n",
    "            Shape (batch_size, dimy)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        input_as_pairs = torch.cat((x_values, y_values), dim=1)\n",
    "        \n",
    "        return self._process_input(input_as_pairs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregator\n",
    "\n",
    "- The aggregator simply creates an aggregation'\n",
    "- Here we simply take the average of ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def aggregate(ri_tensor):\n",
    "    \"\"\"Takes a tensor of shape (batch_size,num_context_points, dimr) and aggregates it a\n",
    "    along the second axis so that we have an aggregation across each batch\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    ri_tensor : Tensor\n",
    "        Tensor of the representation of the x and y context points\n",
    "    \"\"\"\n",
    "    \n",
    "    return ri_tensor.mean(dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "- The decoder takes the context points and the representation, passes them through an MLP and returns an output of dimensions two\n",
    "- These two are used to minimize the negative log conditinal ligelihood which is a function that depends on the mu and sigma\n",
    "- By minimize this quantitiy we find the correct parameters to the distribution of the Gaussian process from which the context points were drawn.\n",
    "- We need to get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    \"\"\"The decoder takes in x_values, that is the target points and combines them with\n",
    "    the represenation of the context points by concatenation. The resulting tensor is passed to an MLP that \n",
    "    is asked to ouput the parameters for the sought after distribution, in this case\n",
    "    a normal distribution. Thus we are looking for two parameters. The MLP returns two tensor obejects\n",
    "    which hold a mean/ variance for each point y. Thus the shape of this output is \n",
    "    batch_size,y_values,y_dim, 2\n",
    "    \n",
    "    Note the targets consist\n",
    "    of both the context points as well as the target points, since the context points\n",
    "    are a subset of the target points.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        \n",
    "    dimx : int\n",
    "        Dimension of each x value\n",
    "    \n",
    "    dimr : int\n",
    "        Dimension of each of the representations\n",
    "    \n",
    "    *args : tuple\n",
    "        Dimensions of the hidden layers \n",
    "             \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,dimx, dimr,dimparam,dimh):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self._dimx = dimx\n",
    "        self._dimr = dimr\n",
    "        self._dimparam = dimparam\n",
    "        self._dimh = dimh\n",
    "        \n",
    "        _first_layer = [nn.Linear(self._dimx+self._dimr, self._dimh[0]),nn.ReLU()]\n",
    "        \n",
    "        _hidden_layers = list(np.array([\n",
    "            [nn.Linear(self._dimh[i], self._dimh[i+1]),nn.ReLU()]\n",
    "            for i in range(len(self._dimh)-1)\n",
    "        ]).flatten())\n",
    "        \n",
    "        _last_layer = [nn.Linear(self._dimh[-1], self._dimparam)]\n",
    "        \n",
    "        self._layers = _first_layer + _hidden_layers + _last_layer\n",
    "        \n",
    "        \n",
    "        self._process_input = nn.Sequential(*self._layers)\n",
    "        \n",
    "    def forward(self, x_values,r_values):\n",
    "        \n",
    "        \"\"\"Takes x and r values, combines them and passes them twice to MLP. \n",
    "        Thus we have one run for mu and one run for sigma\"\"\"\n",
    "        \n",
    "        input_as_pairs = torch.cat((x_values, r_values),dim=1)\n",
    "        \n",
    "        dist_params = self._process_input(input_as_pairs)\n",
    "        return self._process_input(input_as_pairs)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_var(var_tensor):\n",
    "    \n",
    "    '''This function takes a learned variance tensor and transforms \n",
    "    it following the methodology in Empirical Evaluation of Neural Process Objectives.\n",
    "    This ensures that the covariance matrix is positive definite and a multivariate\n",
    "    Gaussian can be constructed.\n",
    "    Next it pads the diagonal with zeroes to create a covariance matrix for sampling.\n",
    "   '''\n",
    "    transformed_variance =  0.1+0.9*softplus(var_tensor)\n",
    "    cov_matrix = torch.diag_embed(transformed_variance)\n",
    "    return cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def calc_loss (mu,sigma, targets):\n",
    "    \"\"\"Takes mean and variance arranges them in the appropriate shapes and creates a multivariate normal\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "        \n",
    "    mu : Tensor\n",
    "        (Batch_size, num_target) dimensional vector with mean estimate for each target\n",
    "    \n",
    "    sigma : Tensor\n",
    "        (Batch_size, num_target) dimensional vector holding the variance estimate for each target\n",
    "            \n",
    "    targets : Tensor \n",
    "        (batch_size,num_targets, ydim) dimensional vector with the targets\n",
    "        \n",
    "        \"\"\"\n",
    "#   padding the variance vector with zeros of the diagonal  \n",
    "    cov_matrix = torch.diag_embed(sigma)\n",
    "    distribution = MultivariateNormal(loc=mu, covariance_matrix=cov_matrix)\n",
    "    loss = distribution.log_prob(targets.squeeze(-1))\n",
    "        \n",
    "    return distribution,torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n_epochs,\n",
    "                 lr,\n",
    "                 max_funcs,\n",
    "                 max_contx,\n",
    "                 min_contx,\n",
    "                 dim_observation,\n",
    "                 dimx=1,\n",
    "                 dimy=1,\n",
    "                 dimr=50,\n",
    "                 dimout=2,\n",
    "                 dim_encoder=[128,128,128],\n",
    "                 dim_decoder=[128,128,128]):\n",
    "        super().__init__()\n",
    "    \n",
    "        self._n_epochs = n_epochs\n",
    "        self._lr = lr\n",
    "        self._max_trgts = max_funcs\n",
    "        self._max_contx = max_contx\n",
    "        self._min_contx = min_contx\n",
    "        self._dim_observation = dim_observation\n",
    "        self._dimx = dimx\n",
    "        self._dimy = dimy\n",
    "        self._dimr = dimr\n",
    "        self._dimout = dimout\n",
    "        self._dim_encoder = dim_encoder\n",
    "        self._dim_decoder = dim_decoder\n",
    "    \n",
    "    def _get_sample_indexes(self):\n",
    "        num_contxt = np.random.randint(self._min_contx, self._max_contx)\n",
    "        num_trgts = np.random.randint(self._max_contx,self._max_trgts)  \n",
    "        trgts_idx = np.random.choice(np.arange(0,self._dim_observation), num_trgts)\n",
    "        contxt_idx = trgts_idx[:num_contxt]\n",
    "        return trgts_idx, contxt_idx\n",
    "    \n",
    "    \n",
    "\n",
    "    def run_training(self, trainloader):\n",
    "        # defining the Encoder and the Decoder nstances\n",
    "        encoder = Encoder(self._dimx, self._dimy, self._dimr, self._dim_encoder)\n",
    "        decoder = Decoder(self._dimx, self._dim_encoder[-1], self._dimout, self._dim_decoder)\n",
    "        \n",
    "        optimizer = optim.Adam(decoder.parameters())\n",
    "        running_loss = []\n",
    "        \n",
    "        for epoch in range(self._n_epochs):\n",
    "            running_loss = 0\n",
    "#         get sample indexes\n",
    "            for xvalues, funcvalues in trainloader:\n",
    "                optimizer.zero_grad()\n",
    "#           we sample for every single batch  \n",
    "#           Setting the batch size here is not ideal\n",
    "                batch_size = xvalues.shape[0]\n",
    "            \n",
    "                func_idx, contxt_idx = self._get_sample_indexes()\n",
    "                num_trgt,num_contxt = len(func_idx),len(contxt_idx)\n",
    "                \n",
    "                target_y = funcvalues[:,func_idx,:]\n",
    "                target_x = xvalues[:,func_idx,:]\n",
    "                \n",
    "                context_y = funcvalues[:,contxt_idx,:]\n",
    "                context_x = xvalues[:,contxt_idx,:]\n",
    "                \n",
    "                # the encoding is stacked to ensure a one dimensional input\n",
    "                context_y_stacked = context_y.view(batch_size*num_contxt,-1)\n",
    "                context_x_stacked = context_x.view(batch_size*num_contxt,-1)\n",
    "\n",
    "                # running the context values through the encoding\n",
    "                encoding  = encoder(context_x_stacked,context_y_stacked)\n",
    "                encoding  = encoding.view(batch_size,num_contxt,-1)\n",
    "                # averaging the encoding \n",
    "                encoding_avg  = encoding.mean(1)\n",
    "                # we need to unsqueeze and repeat the embedding\n",
    "                # because we need to pair it with every target\n",
    "                encoding_avg  = encoding_avg.unsqueeze(1)\n",
    "                encoding_exp  = encoding_avg.repeat(1,num_trgt,1)\n",
    "\n",
    "                encoding_stacked = encoding_exp.view(batch_size*num_trgt,-1)\n",
    "                target_x_stacked = target_x.view(batch_size*num_trgt,-1)\n",
    "                \n",
    "                decoding = decoder(target_x_stacked,encoding_stacked)\n",
    "                decoding_rshp = decoding.view(batch_size,num_trgt,-1)\n",
    "                \n",
    "#              \n",
    "                mu,sigma = decoding_rshp[:,:,0], decoding_rshp[:,:,1]\n",
    "                cov_matrix = transform_var(sigma)    \n",
    "                distribution = MultivariateNormal(loc=mu, covariance_matrix=cov_matrix)\n",
    "                loss = torch.mean(distribution.log_prob(target_y.squeeze(-1)))\n",
    "                running_loss += loss\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(running_loss/len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(10, 0.001,50,20,5,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-53.2720, grad_fn=<DivBackward0>)\n",
      "tensor(-58.3410, grad_fn=<DivBackward0>)\n",
      "tensor(-450.0417, grad_fn=<DivBackward0>)\n",
      "tensor(-9757.7109, grad_fn=<DivBackward0>)\n",
      "tensor(-84206.6875, grad_fn=<DivBackward0>)\n",
      "tensor(-955951., grad_fn=<DivBackward0>)\n",
      "tensor(-6322273., grad_fn=<DivBackward0>)\n",
      "tensor(-27677392., grad_fn=<DivBackward0>)\n",
      "tensor(-1.3434e+08, grad_fn=<DivBackward0>)\n",
      "tensor(-3.9243e+08, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "t = trainer.run_training(one_d_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_d_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].log_prob(t[1].squeeze(-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (38) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2f159f18e73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.7/site-packages/torch/distributions/utils.py\u001b[0m in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     31\u001b[0m         values = [v if torch.is_tensor(v) else torch.tensor(v, **options)\n\u001b[1;32m     32\u001b[0m                   for v in values]\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (38) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "t = Normal(mu_t,sigma_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 38, 38])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([64, 39]), covariance_matrix: torch.Size([64, 39, 39]))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultivariateNormal(t[0],torch.diag_embed(t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'embed_diag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-aec84927c043>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'embed_diag'"
     ]
    }
   ],
   "source": [
    "torch.embed_diag(sigma_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "covariance_matrix must be at least two-dimensional, with optional leading batch dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-15e0964dbd2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.7/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcovariance_matrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                 raise ValueError(\"covariance_matrix must be at least two-dimensional, \"\n\u001b[0m\u001b[1;32m    134\u001b[0m                                  \"with optional leading batch dimensions\")\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: covariance_matrix must be at least two-dimensional, with optional leading batch dimensions"
     ]
    }
   ],
   "source": [
    "MultivariateNormal(loc=mut,covariance_matrix=sigma_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " ## Sandbox - testing the individual parts of the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Kernel function\n",
    "Expanding the dimesions of the tensors allows us substract each point pairwise\n",
    "This being a 1-D use case we simply substract each of the data points and get an n by n matrix for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 20])\n",
      "torch.Size([64, 10, 20])\n",
      "torch.Size([640, 20])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_points = 10\n",
    "dimx = 1\n",
    "dimy = 1\n",
    "rdim = 20\n",
    "hdim = 20\n",
    "x = Helper.scale_shift_uniform(-2,2,batch_size,num_points,dimx)\n",
    "y = Helper.scale_shift_uniform(-2,2,batch_size,num_points,dimy)\n",
    "\n",
    "x_stacked  = x.view(batch_size*num_points,-1)\n",
    "y_stacked  = y.view(batch_size*num_points,-1)\n",
    "encoder = Encoder(1,1,hdim,[hdim,hdim,rdim])\n",
    "r  = encoder.forward(x_stacked,y_stacked)\n",
    "r = r.view(batch_size,num_points,-1)\n",
    "r_aggregate = aggregate(r).unsqueeze(1)\n",
    "print(r_aggregate.shape)\n",
    "r_aggregate = r_aggregate.repeat(1,num_points,1)\n",
    "print(r_aggregate.shape)\n",
    "\n",
    "hdim = 128\n",
    "outdim = 2\n",
    "decoder = Decoder(dimx,rdim,outdim,[hdim,hdim,hdim])\n",
    "\n",
    "r_stacked = r_aggregate.view(batch_size*num_points,-1)\n",
    "print(r_stacked.shape)\n",
    "dist_params = decoder.forward(x_stacked, r_stacked).view(batch_size,num_points,-1)\n",
    "\n",
    "mu = dist_params[:,:,0]\n",
    "sigma = torch.diag_embed(dist_params[:,:,1])\n",
    "sigma_test = torch.ones(10).unsqueeze(0).repeat(64,1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}