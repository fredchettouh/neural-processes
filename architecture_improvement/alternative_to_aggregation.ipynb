{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Colab?\n",
      "noi\n",
      "Top level directory is set to /Users/frederik/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "google_colab = input('Running on Colab?\\n')\n",
    "if google_colab=='yes' : \n",
    "    BASE_DIR = 'University/UC3M/TFM/cnp_repo/neural-processes'\n",
    "\n",
    "    # Load the Drive helper and mount\n",
    "    from google.colab import drive\n",
    "\n",
    "    # This will prompt for authorization.\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "      # Change to assignment directory ('Lab_Exercises_DASS/Lab_Exercise4' by default)\n",
    "    import os\n",
    "    os.chdir(f'/content/drive/My Drive/{BASE_DIR}')\n",
    "    \n",
    "else:\n",
    "    import sys, os \n",
    "    BASE_DIR = '/'.join(os.getcwd().split('/')[:-1])\n",
    "    sys.path.append(BASE_DIR)\n",
    "    print(f'Top level directory is set to {BASE_DIR}')\n",
    "    os.chdir(BASE_DIR)\n",
    "\n",
    "    \n",
    "# custom imports\n",
    "from cnp.trainer import RegressionTrainer\n",
    "from cnp.datageneration import DataGenerator\n",
    "from cnp.helpers import Helper\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# import utils\n",
    "import json\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we first get the variables for the configuration file\n",
    "os.environ[\"CHECKPOINT_DIR\"] = \"checkpoints\"\n",
    "os.environ[\"MODEL_PARAMS\"] = \"default\"\n",
    "\n",
    "CHECKPOINT_DIR = os.environ['CHECKPOINT_DIR']\n",
    "MODEL_PARAMS = os.environ['MODEL_PARAMS']\n",
    "\n",
    "if google_colab=='yes':\n",
    "    config_dir = ''\n",
    "else:\n",
    "    config_dir = os.path.join(BASE_DIR,'configs')\n",
    "\n",
    "with open(os.path.join(config_dir,'1d_singlefunc_config.json')) as f:\n",
    "    file = f.read()\n",
    "    default_conf = json.loads(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# checking whether CUDA is available \n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "    default_conf['single_function']['experiment_params']['train_on_gpu'] = True\n",
    "else: \n",
    "    print('No GPU available, training on CPU')\n",
    "    default_conf['single_function']['experiment_params']['train_on_gpu'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_conf['single_function']['training_params']['kwargs']['data_path'] = os.path.join(\n",
    "    BASE_DIR,\n",
    "    default_conf['single_function']['training_params']['kwargs']['data_dir'],\n",
    "     default_conf['single_function']['training_params']['kwargs']['extension'],\n",
    "    default_conf['single_function']['training_params']['kwargs']['data_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will first try to replicate what we have after one encoding step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from cnp.networks import Encoder, create_linear_layer\n",
    "from cnp.cnp import get_sample_indexes, select_data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, y_train, X_vali, y_vali = Helper.read_and_transform(\n",
    "    default_conf['single_function']['training_params']['kwargs']['data_path'],\n",
    "    'target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = Helper.create_loader(X_train, y_train, batch_size)\n",
    "valiloader = Helper.create_loader(X_vali, y_vali, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalues = X_train[:50,:]\n",
    "funcvalues = y_train[:50]\n",
    "xvalues = xvalues.unsqueeze(0)\n",
    "funcvalues = funcvalues[None, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_specs_kwargs = {\n",
    "            \"min_trgts\": default_conf['single_function']['experiment_params']['min_funcs'],\n",
    "            \"max_trgts\": default_conf['single_function']['experiment_params']['max_funcs'],\n",
    "            \"max_contx\": default_conf['single_function']['experiment_params']['max_contx'],\n",
    "            \"min_contx\": default_conf['single_function']['experiment_params']['min_contx']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_idx, contxt_idx = get_sample_indexes(\n",
    "    **sample_specs_kwargs,\n",
    "    dim_observation=default_conf['single_function']['experiment_params']['dim_observation']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_small = xvalues.shape[0]\n",
    "um_contxt, num_trgt, target_x, target_y, context_x_stacked,context_y_stacked, target_x_stacked = select_data(\n",
    "            contxt_idx, func_idx, xvalues,\n",
    "            funcvalues, batch_size_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(dimx=1, dimy=1, dimr=128, num_layers=3, num_neurons=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When we are taking the mean we say that each context point is equally important \n",
    "- When we parametize this function we say that not each point is equally important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Aggregator(nn.Module):\n",
    "        def __init__(\n",
    "            self,\n",
    "            maxcontxt: int,\n",
    "            dimout: int,\n",
    "            num_layers: int,\n",
    "            num_neurons: int,\n",
    "            dropout: float = 0) -> None:\n",
    "\n",
    "            super().__init__()\n",
    "            self._dimr = maxcontxt\n",
    "            self._dimout= dimout\n",
    "            self._hidden_layers = [num_neurons for _ in range(num_layers)]\n",
    "\n",
    "            _first_layer = [\n",
    "                nn.Linear(self._dimr, self._hidden_layers[0]),\n",
    "                nn.ReLU()]\n",
    "            _hidden_layers = [\n",
    "                create_linear_layer(self._hidden_layers, i, dropout)\n",
    "                for i in range(len(self._hidden_layers) - 2)]\n",
    "            _hidden_layers_flat = [\n",
    "                element for inner in _hidden_layers for element in inner]\n",
    "\n",
    "            _last_layer = [\n",
    "                nn.Linear(self._hidden_layers[-2], self._dimout)]\n",
    "\n",
    "            self._layers = _first_layer + _hidden_layers_flat + _last_layer\n",
    "\n",
    "            self._process_input = nn.Sequential(*self._layers)\n",
    "            \n",
    "        def forward(self, embedding):\n",
    "            \"\"\"\n",
    "            Parameters\n",
    "            ----------\n",
    "            embedding: torch.Tensor: Shape (batch_size*num_contxt, dimr)\n",
    "\n",
    "            \"\"\"\n",
    "            return self._process_input(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = encoder(context_x_stacked, context_y_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = torch.transpose(encoding,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 7])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_exp = encoding[None,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_padded = zero_padding(encoding_exp, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(source, target_dims):\n",
    "    batch__size, n_observations, n_features = source.size()\n",
    "    zero_target = torch.zeros(batch__size, n_observations, target_dims)\n",
    "    zero_target[:,:,:n_features] = source\n",
    "    return  zero_target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr = Aggregator(maxcontxt=10, dimout=1, num_layers=4, num_neurons=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 1])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggr(encoding_padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[None, :,:].mean(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_uc3m",
   "language": "python",
   "name": "ml_uc3m"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
