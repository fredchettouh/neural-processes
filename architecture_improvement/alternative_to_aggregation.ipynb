{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Colab?\n",
      "\n",
      "Top level directory is set to /Users/frederik/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes\n"
     ]
    }
   ],
   "source": [
    " #%%\n",
    "\n",
    "# google colab configurations \n",
    "# these might change\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "\n",
    "# import utils\n",
    "import json\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "google_colab = input('Running on Colab?\\n')\n",
    "if google_colab=='yes' : \n",
    "\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "\n",
    "\n",
    "    COLAB_CONFIG = '1o5nZNVmNBq3UQRxwYIwOATX0c0GyHPRN'\n",
    "    COLAB_CONFIG_FILE ='colab_config.json'\n",
    "\n",
    "    colab_json = drive.CreateFile({'id': COLAB_CONFIG})\n",
    "    colab_json.GetContentFile(COLAB_CONFIG_FILE)\n",
    "\n",
    "    with open(COLAB_CONFIG_FILE) as f:\n",
    "        temp = f.read()\n",
    "    colab_config = json.loads(temp)\n",
    "\n",
    "    for key in colab_config:\n",
    "        globals()[key] = drive.CreateFile({\"id\":colab_config[key]['id']})\n",
    "        globals()[key].GetContentFile(colab_config[key]['file'])\n",
    "\n",
    "    from trainer import RegressionTrainer\n",
    "    from datageneration import DataGenerator\n",
    "    from helpers import Helper, Plotter\n",
    "    \n",
    "else:\n",
    "    import sys, os \n",
    "    BASE_DIR = '/'.join(os.getcwd().split('/')[:-1])\n",
    "    sys.path.append(BASE_DIR)\n",
    "    print(f'Top level directory is set to {BASE_DIR}')\n",
    "\n",
    "    # custom imports\n",
    "    from cnp.trainer import RegressionTrainer\n",
    "    from cnp.datageneration import DataGenerator\n",
    "    from cnp.helpers import Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we first get the variables for the configuration file\n",
    "os.environ[\"CHECKPOINT_DIR\"] = \"checkpoints\"\n",
    "os.environ[\"MODEL_PARAMS\"] = \"default\"\n",
    "\n",
    "CHECKPOINT_DIR = os.environ['CHECKPOINT_DIR']\n",
    "MODEL_PARAMS = os.environ['MODEL_PARAMS']\n",
    "\n",
    "if google_colab=='yes':\n",
    "    config_dir = ''\n",
    "else:\n",
    "    config_dir = os.path.join(BASE_DIR,'configs')\n",
    "\n",
    "with open(os.path.join(config_dir,'1d_singlefunc_config.json')) as f:\n",
    "    file = f.read()\n",
    "    default_conf = json.loads(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# checking whether CUDA is available \n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "    default_conf['single_function']['experiment_params']['train_on_gpu'] = True\n",
    "else: \n",
    "    print('No GPU available, training on CPU')\n",
    "    default_conf['single_function']['experiment_params']['train_on_gpu'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_conf['single_function']['training_params']['kwargs']['data_path'] = os.path.join(\n",
    "    BASE_DIR,\n",
    "    default_conf['single_function']['training_params']['kwargs']['data_dir'],\n",
    "     default_conf['single_function']['training_params']['kwargs']['extension'],\n",
    "    default_conf['single_function']['training_params']['kwargs']['data_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will first try to replicate what we have after one encoding step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from cnp.networks import Encoder\n",
    "from cnp.cnp import get_sample_indexes, select_data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, y_train, X_vali, y_vali = Helper.read_and_transform(\n",
    "    default_conf['single_function']['training_params']['kwargs']['data_path'],\n",
    "    'target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = Helper.create_loader(X_train, y_train, batch_size)\n",
    "valiloader = Helper.create_loader(X_vali, y_vali, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalues = X_train[:50,:]\n",
    "funcvalues = y_train[:50]\n",
    "xvalues = xvalues.unsqueeze(0)\n",
    "funcvalues = funcvalues[None, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcvalues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_specs_kwargs = {\n",
    "            \"min_trgts\": default_conf['single_function']['experiment_params']['min_funcs'],\n",
    "            \"max_trgts\": default_conf['single_function']['experiment_params']['max_funcs'],\n",
    "            \"max_contx\": default_conf['single_function']['experiment_params']['max_contx'],\n",
    "            \"min_contx\": default_conf['single_function']['experiment_params']['min_contx']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_idx, contxt_idx = get_sample_indexes(\n",
    "    **sample_specs_kwargs,\n",
    "    dim_observation=default_conf['single_function']['experiment_params']['dim_observation']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_small = xvalues.shape[0]\n",
    "um_contxt, num_trgt, target_x, target_y, context_x_stacked,context_y_stacked, target_x_stacked = select_data(\n",
    "            contxt_idx, func_idx, xvalues,\n",
    "            funcvalues, batch_size_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(dimx=1, dimy=1, dimr=128, num_layers=3, num_neurons=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = encoder(context_x_stacked, context_y_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Encoder(\n",
       "  (_process_input): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder._layers[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_uc3m",
   "language": "python",
   "name": "ml_uc3m"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
