{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Colab?\n",
      "o\n",
      "Top level directory is set to /Users/frederik/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "google_colab = input('Running on Colab?\\n')\n",
    "if google_colab=='yes' : \n",
    "    BASE_DIR = 'University/UC3M/TFM/cnp_repo/neural-processes'\n",
    "\n",
    "    # Load the Drive helper and mount\n",
    "    from google.colab import drive\n",
    "\n",
    "    # This will prompt for authorization.\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "      # Change to assignment directory ('Lab_Exercises_DASS/Lab_Exercise4' by default)\n",
    "    import os\n",
    "    os.chdir(f'/content/drive/My Drive/{BASE_DIR}')\n",
    "    \n",
    "else:\n",
    "    import sys, os \n",
    "    BASE_DIR = '/'.join(os.getcwd().split('/')[:-1])\n",
    "    sys.path.append(BASE_DIR)\n",
    "    print(f'Top level directory is set to {BASE_DIR}')\n",
    "    os.chdir(BASE_DIR)\n",
    "\n",
    "    \n",
    "# custom imports\n",
    "from cnp.trainer import RegressionTrainer\n",
    "from cnp.datageneration import DataGenerator\n",
    "from cnp.helpers import Helper\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# import utils\n",
    "import json\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we first get the variables for the configuration file\n",
    "os.environ[\"CHECKPOINT_DIR\"] = \"checkpoints\"\n",
    "os.environ[\"MODEL_PARAMS\"] = \"default\"\n",
    "\n",
    "CHECKPOINT_DIR = os.environ['CHECKPOINT_DIR']\n",
    "MODEL_PARAMS = os.environ['MODEL_PARAMS']\n",
    "\n",
    "if google_colab=='yes':\n",
    "    config_dir = ''\n",
    "else:\n",
    "    config_dir = os.path.join(BASE_DIR,'configs')\n",
    "\n",
    "with open(os.path.join(config_dir,'1dpolynomial_fixedcontxt_mlpaggr.json')) as f:\n",
    "    file = f.read()\n",
    "    default_conf = json.loads(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# checking whether CUDA is available \n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "    default_conf['experiment_params']['train_on_gpu'] = True\n",
    "else: \n",
    "    print('No GPU available, training on CPU')\n",
    "    default_conf['experiment_params']['train_on_gpu'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will first try to replicate what we have after one encoding step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from cnp.networks import Encoder, create_linear_layer\n",
    "from cnp.cnp import get_sample_indexes, select_data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from cnp.datageneration import PolynomialRegression, DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cnp_params': {'dimout': 2,\n",
       "  'dimr': 128,\n",
       "  'dimx': 1,\n",
       "  'dimy': 1,\n",
       "  'dropout': 0,\n",
       "  'max_contx': 10,\n",
       "  'max_funcs': 10,\n",
       "  'min_contx': 3,\n",
       "  'min_funcs': 2,\n",
       "  'fix_num_contxt': True,\n",
       "  'num_layers_decoder': 3,\n",
       "  'num_layers_encoder': 4,\n",
       "  'num_neurons_decoder': 128,\n",
       "  'num_neurons_encoder': 128,\n",
       "  'aggregation_kwargs': {'aggregator': 'MLPAggregator',\n",
       "   'insize': 5,\n",
       "   'dimout': 1,\n",
       "   'num_layers': 2,\n",
       "   'num_neurons': 20,\n",
       "   'padding': False}},\n",
       " 'data_kwargs': {'datagenerator': 'cnp.datageneration.PolynomialRegression',\n",
       "  'mu': 0,\n",
       "  'sigma': 2,\n",
       "  'num_instances_train': 64,\n",
       "  'num_instances_vali': 1,\n",
       "  'num_instances_test': 1},\n",
       " 'experiment_params': {'dim_observation': 50,\n",
       "  'lr': 0.001,\n",
       "  'n_epochs': 10000,\n",
       "  'range_x': [-2, 2],\n",
       "  'seed': None,\n",
       "  'dimx': 1,\n",
       "  'train_on_gpu': False},\n",
       " 'train_kwargs': {'batch_size_train': 64,\n",
       "  'batch_size_vali': 1,\n",
       "  'batch_size_test': 1,\n",
       "  'plotting': True,\n",
       "  'print_after': 100}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = DataGenerator(xdim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_create_x',\n",
       " '_steps',\n",
       " '_xdim',\n",
       " '_xmax',\n",
       " '_xmin',\n",
       " 'generate_curves',\n",
       " 'generate_from_single_function',\n",
       " 'generate_loader_on_fly']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9900, -1.9900, -1.9900, -1.9900, -1.9900])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen._create_x()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_function(num_polynomials=2,num_dims=2):\n",
    "    x_data = torch.linspace(-2, 2,400)\n",
    "    x_data = x_data.unsqueeze(-1)\n",
    "    x_data = x_data.repeat(1, num_dims)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_uc3m",
   "language": "python",
   "name": "ml_uc3m"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
